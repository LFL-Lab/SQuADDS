{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tutorial 3: Machine Learning with `SQuADDS`\n",
    "\n",
    "In this tutorial, we will walk you through how to use SQuADDS to create ML interpolation solutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Training Data from `SQuADDS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we will be trying to predict the design space variables of a qubit-cavity system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from squadds import SQuADDS_DB, Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQuADDS_DB()\n",
    "db.select_system([\"qubit\",\"cavity_claw\"])\n",
    "db.select_qubit(\"TransmonCross\")\n",
    "db.select_cavity_claw(\"RouteMeander\")\n",
    "db.select_resonator_type(\"quarter\")\n",
    "merged_df = db.create_system_df()\n",
    "analyzer = Analyzer(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we need all Hamiltonian parameters to generate a **complete** training dataset. For this tutorial, I have chosen some demo targets to generate the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_data_df = pd.read_csv('data/seed_data.csv')\n",
    "seed_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the training data using this `seed_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from squadds.interpolations.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = generate_qubit_cavity_training_data(analyzer, seed_data_df,\"data/training_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.columns, training_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the `training_df` has information about both the design space variables (**our targets**) and its corresponding Hamiltonian parameters (**our features**).\n",
    "\n",
    "Now, we are ready to train an ML model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import the usual \"suspects\" in the ML world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from huggingface_hub import hf_hub_download\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_parquet(\"data/training_data.parquet\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there should not be any duplicates in the training data, we will remove them just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the duplicate rows\n",
    "training_df = training_df.drop_duplicates()\n",
    "\n",
    "# reset the index\n",
    "training_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the data into features (`X` - the Hamiltonian parameters) and targets (`y` - the design space variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_df[['qubit_frequency_GHz', 'anharmonicity_MHz', 'cavity_frequency_GHz', 'kappa_kHz', 'g_MHz']].values\n",
    "y = training_df[['cross_length', 'claw_length','coupling_length', 'total_length','ground_spacing']].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to capture the polynomial features of the data, so we will use the `PolynomialFeatures` class from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Save the polynomial feature transformer\n",
    "joblib.dump(poly, 'models/poly_transformer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to normalize both the features and the target values. This ensures that all data is on the same scale, which helps the model learn more effectively. We use `StandardScaler` from `sklearn.preprocessing` to:\n",
    "\n",
    "- **Fit and transform** the training data.\n",
    "- **Transform** the test data using the same scaler.\n",
    "- **Scale the target values** to ensure consistency.\n",
    "\n",
    "Finally, we save the scalers so they can be reused later during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "\n",
    "X_train_poly = scaler_X.fit_transform(X_train_poly)\n",
    "X_test_poly = scaler_X.transform(X_test_poly)\n",
    "\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n",
    "\n",
    "# Save the scalers\n",
    "joblib.dump(scaler_X, 'models/scaler_X.pkl')\n",
    "joblib.dump(scaler_y, 'models/scaler_y.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Model Training:\n",
    "\n",
    "### Simple Deep Neural Network (DNN)\n",
    "\n",
    "We'll begin with a simple deep neural network (DNN) to predict the design space variables (`y`) from the Hamiltonian parameters (`X`).\n",
    "\n",
    "- The model consists of three hidden layers:\n",
    "  - 256, 128, and 64 neurons, respectively.\n",
    "  - Each layer uses ReLU activation.\n",
    "- To improve generalization and reduce overfitting:\n",
    "  - **Batch Normalization** is applied after each layer.\n",
    "  - **Dropout (30%)** is applied after each layer.\n",
    "- The output layer matches the number of design variables.\n",
    "- The optimizer used is **Adam** with a learning rate of 0.001, and the loss function is **mean squared error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_dnn_model(neurons1=256, neurons2=128, neurons3=64, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons1, input_dim=X_train_poly.shape[1], activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(neurons2, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(neurons3, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(y_train.shape[1]))  # Output layer with the same number of neurons as output features\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will train the DNN model on the training data for up to 500 epochs.\n",
    "\n",
    "To ensure we save the best performing model, we have added a **ModelCheckpoint** callback that saves the model whenever the validation loss improves.\n",
    "\n",
    "Additionally, we’ve added an **EarlyStopping** callback to stop training if the validation loss doesn’t improve for 10 consecutive epochs. This helps prevent overfitting and reduces unnecessary training time by restoring the model's weights to the best epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for early stopping and model checkpoint\n",
    "model_checkpoint = ModelCheckpoint('models/simple_dnn.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, mode='min')\n",
    "\n",
    "# Train the model on the entire training data with callbacks\n",
    "dnn = simple_dnn_model()\n",
    "history = dnn.fit(X_train_poly, y_train, epochs=500, batch_size=16, verbose=1, validation_split=0.2, callbacks=[model_checkpoint,early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the training history to see how the model performed during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv('models/dnn_training_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('figures/dnn_training_validation_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can evaluate the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test data\n",
    "test_mse = dnn.evaluate(X_test_poly, y_test, verbose=0)\n",
    "\n",
    "# Predictions\n",
    "y_pred = dnn.predict(X_test_poly)\n",
    "\n",
    "\n",
    "# Inverse transform the predictions and actual values to get them back to original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred)\n",
    "y_test = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual values for each target variable\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(y_test.shape[1]):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.scatter(y_test[:, i], y_pred[:, i], alpha=0.5)\n",
    "    plt.plot([min(y_test[:, i]), max(y_test[:, i])], [min(y_test[:, i]), max(y_test[:, i])], 'r')\n",
    "    plt.title(f'Target Variable {i+1}')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/dnn_predicted_vs_actual.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool to see that such a basic model can generally capture the trends in the data (sort of haha). Of course, we can always improve the model by tuning the hyperparameters, adding more data, or using more sophisticated models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model performs on some different data points so that we can compare it to the scaling interpolation algorithm and the closest simulation results. First, lets load the test dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(f\"data/test_data.csv\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the trained model to predict the design space variables for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract input features\n",
    "X_test = test_data[['qubit_frequency_GHz', 'anharmonicity_MHz', 'cavity_frequency_GHz', 'kappa_kHz', 'g_MHz']].values\n",
    "\n",
    "# Transform input features\n",
    "X_test_poly = poly.transform(X_test)\n",
    "X_test_poly = scaler_X.transform(X_test_poly)\n",
    "\n",
    "# Make predictions with the DNN model\n",
    "y_pred_dnn = scaler_y.inverse_transform(dnn.predict(X_test_poly))\n",
    "\n",
    "# save the predictions for future use\n",
    "np.savetxt(\"data/y_pred_dnn.csv\", y_pred_dnn, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the corresponding scaling interpolation and closest simulation data points for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_df = pd.read_csv(\"data/scaling_interp_data.csv\", index_col=0)\n",
    "interp_df.columns = ['total_length', 'coupling_length', 'cross_length', 'claw_length', 'Ej', 'ground_spacing']\n",
    "\n",
    "# Sort to match the order of target_names\n",
    "scaling_interp_pred = interp_df[['cross_length', 'claw_length', 'coupling_length', 'total_length', 'ground_spacing']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_df = pd.read_csv(\"data/closest_sim_data.csv\", index_col=0)\n",
    "closest_df.columns = ['total_length', 'coupling_length', 'cross_length', 'claw_length', 'ground_spacing', 'Ej']\n",
    "\n",
    "# Sort to match the order of target_names\n",
    "closest_results = closest_df[['cross_length', 'claw_length', 'coupling_length', 'total_length', 'ground_spacing']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moments of truth! Let's see how the model performs on the new data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "colors = sns.color_palette(\"husl\", 3)  # Get a palette with 3 different hues\n",
    "\n",
    "# Plot comparisons of predicted values\n",
    "target_names = ['cross_length', 'claw_length',  'coupling_length', 'total_length', 'ground_spacing']\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n",
    "for i, target_name in enumerate(target_names):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.plot(y_pred_dnn[:, i], label='ML', color=colors[0], linewidth=2)\n",
    "    plt.plot(scaling_interp_pred[:, i], label='Physics', color=colors[1], linewidth=2, linestyle=':')\n",
    "    plt.plot(closest_results[:, i], label='Closest', color=colors[2], linewidth=2, linestyle='-.')\n",
    "    plt.ylabel(r'$\\mu m$', fontsize=16)\n",
    "    # Adding title and customizing fonts\n",
    "    plt.title(f'{target_name}', fontsize=20, weight='bold')\n",
    "    plt.xlabel('Targets', fontsize=16)\n",
    "\n",
    "    # Improve legends\n",
    "    plt.legend(loc='upper right', fontsize=12, fancybox=True, framealpha=0.5)\n",
    "\n",
    "    # Adding grid and minor ticks for better readability\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.minorticks_on()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/comparison_predicted_values.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate and Benchmark the ML Model\n",
    "\n",
    "To truly evaluate the model's performance, we need to simulate the qubit-cavity system using the predicted design space variables and compute the corresponding Hamiltonian parameters and see how they compare to the target Hamiltonian parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e ../."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from squadds import SQuADDS_DB, Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62812ba0a213474bb2c5b025e3e6d0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbd4af234f44485a48d07a691a8e30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dc2bcd89ad44b79d09ae04c575275c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db = SQuADDS_DB()\n",
    "db.select_system([\"qubit\",\"cavity_claw\"])\n",
    "db.select_qubit(\"TransmonCross\")\n",
    "db.select_cavity_claw(\"RouteMeander\")\n",
    "db.select_resonator_type(\"quarter\")\n",
    "merged_df = db.create_system_df()\n",
    "analyzer = Analyzer(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dnn = np.loadtxt(\"/Users/shanto/LFL/SQuADDS/qiskit_fall_event/data/y_pred_dnn.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(f\"/Users/shanto/LFL/SQuADDS/qiskit_fall_event/data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following method to extract the `designs_df` that we will use to simulate the qubit-cavity system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to add the coupled H params: 4.216215133666992 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coupler_type</th>\n",
       "      <th>design_options_qubit</th>\n",
       "      <th>design_options_cavity_claw</th>\n",
       "      <th>setup_qubit</th>\n",
       "      <th>setup_cavity_claw</th>\n",
       "      <th>design_options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLT</td>\n",
       "      <td>{'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...</td>\n",
       "      <td>{'claw_opts': {'connection_pads': {'readout': ...</td>\n",
       "      <td>{'auto_increase_solution_order': True, 'enable...</td>\n",
       "      <td>{'basis_order': 1, 'max_delta_f': 0.05, 'max_p...</td>\n",
       "      <td>{'cavity_claw_options': {'coupler_type': 'CLT'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLT</td>\n",
       "      <td>{'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...</td>\n",
       "      <td>{'claw_opts': {'connection_pads': {'readout': ...</td>\n",
       "      <td>{'auto_increase_solution_order': True, 'enable...</td>\n",
       "      <td>{'basis_order': 1, 'max_delta_f': 0.05, 'max_p...</td>\n",
       "      <td>{'cavity_claw_options': {'coupler_type': 'CLT'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLT</td>\n",
       "      <td>{'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...</td>\n",
       "      <td>{'claw_opts': {'connection_pads': {'readout': ...</td>\n",
       "      <td>{'auto_increase_solution_order': True, 'enable...</td>\n",
       "      <td>{'basis_order': 1, 'max_delta_f': 0.05, 'max_p...</td>\n",
       "      <td>{'cavity_claw_options': {'coupler_type': 'CLT'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CLT</td>\n",
       "      <td>{'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...</td>\n",
       "      <td>{'claw_opts': {'connection_pads': {'readout': ...</td>\n",
       "      <td>{'auto_increase_solution_order': True, 'enable...</td>\n",
       "      <td>{'basis_order': 1, 'max_delta_f': 0.05, 'max_p...</td>\n",
       "      <td>{'cavity_claw_options': {'coupler_type': 'CLT'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CLT</td>\n",
       "      <td>{'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...</td>\n",
       "      <td>{'claw_opts': {'connection_pads': {'readout': ...</td>\n",
       "      <td>{'auto_increase_solution_order': True, 'enable...</td>\n",
       "      <td>{'basis_order': 1, 'max_delta_f': 0.05, 'max_p...</td>\n",
       "      <td>{'cavity_claw_options': {'coupler_type': 'CLT'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CLT</td>\n",
       "      <td>{'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...</td>\n",
       "      <td>{'claw_opts': {'connection_pads': {'readout': ...</td>\n",
       "      <td>{'auto_increase_solution_order': True, 'enable...</td>\n",
       "      <td>{'basis_order': 1, 'max_delta_f': 0.05, 'max_p...</td>\n",
       "      <td>{'cavity_claw_options': {'coupler_type': 'CLT'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  coupler_type                               design_options_qubit  \\\n",
       "0          CLT  {'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...   \n",
       "1          CLT  {'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...   \n",
       "2          CLT  {'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...   \n",
       "3          CLT  {'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...   \n",
       "4          CLT  {'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...   \n",
       "5          CLT  {'aedt_hfss_capacitance': 0, 'aedt_hfss_induct...   \n",
       "\n",
       "                          design_options_cavity_claw  \\\n",
       "0  {'claw_opts': {'connection_pads': {'readout': ...   \n",
       "1  {'claw_opts': {'connection_pads': {'readout': ...   \n",
       "2  {'claw_opts': {'connection_pads': {'readout': ...   \n",
       "3  {'claw_opts': {'connection_pads': {'readout': ...   \n",
       "4  {'claw_opts': {'connection_pads': {'readout': ...   \n",
       "5  {'claw_opts': {'connection_pads': {'readout': ...   \n",
       "\n",
       "                                         setup_qubit  \\\n",
       "0  {'auto_increase_solution_order': True, 'enable...   \n",
       "1  {'auto_increase_solution_order': True, 'enable...   \n",
       "2  {'auto_increase_solution_order': True, 'enable...   \n",
       "3  {'auto_increase_solution_order': True, 'enable...   \n",
       "4  {'auto_increase_solution_order': True, 'enable...   \n",
       "5  {'auto_increase_solution_order': True, 'enable...   \n",
       "\n",
       "                                   setup_cavity_claw  \\\n",
       "0  {'basis_order': 1, 'max_delta_f': 0.05, 'max_p...   \n",
       "1  {'basis_order': 1, 'max_delta_f': 0.05, 'max_p...   \n",
       "2  {'basis_order': 1, 'max_delta_f': 0.05, 'max_p...   \n",
       "3  {'basis_order': 1, 'max_delta_f': 0.05, 'max_p...   \n",
       "4  {'basis_order': 1, 'max_delta_f': 0.05, 'max_p...   \n",
       "5  {'basis_order': 1, 'max_delta_f': 0.05, 'max_p...   \n",
       "\n",
       "                                      design_options  \n",
       "0  {'cavity_claw_options': {'coupler_type': 'CLT'...  \n",
       "1  {'cavity_claw_options': {'coupler_type': 'CLT'...  \n",
       "2  {'cavity_claw_options': {'coupler_type': 'CLT'...  \n",
       "3  {'cavity_claw_options': {'coupler_type': 'CLT'...  \n",
       "4  {'cavity_claw_options': {'coupler_type': 'CLT'...  \n",
       "5  {'cavity_claw_options': {'coupler_type': 'CLT'...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from squadds.interpolations.utils import get_design_from_ml_predictions\n",
    "\n",
    "designs_df = get_design_from_ml_predictions(analyzer, test_data, y_pred_dnn)\n",
    "designs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ansys Simulation\n",
    "\n",
    "Now to simulate each design in the `designs_df` in Ansys and extract the Hamiltonian parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from squadds import AnsysSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:UserWarning: `AnsysSimulator` is not supported on MacOS since Ansys does not have a Mac App. Please use Windows or Linux for simulations.\n",
      " /Users/shanto/LFL/SQuADDS/SQuADDS/squadds/simulations/ansys_simulator.py: 94\n",
      "08:24PM 41s WARNING [__init__]: Component claw does not exist. cpw has not been built. Please check your pin_input values.\n",
      "WARNING:py.warnings:RuntimeWarning: invalid value encountered in divide\n",
      " /Users/shanto/LFL/SQuADDS/test_squadds/src/qiskit-metal/qiskit_metal/draw/utility.py: 607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating design 0\n",
      "selected system: ['qubit', 'cavity_claw']\n",
      "\n",
      "HERE\n",
      "{'connection_pads': {'readout': {'claw_cpw_length': '0um', 'claw_cpw_width': '0um', 'claw_gap': '5.1um', 'claw_length': '183.19662475585938um', 'claw_width': '15um', 'connector_location': '90', 'connector_type': '0', 'ground_spacing': '4.838527679443359um', 'Lj': '9.999943819504589nH'}}, 'cross_gap': '0um', 'cross_length': '0um', 'cross_width': '0um', 'orientation': '-90', 'pos_x': '-1500um'}\n",
      "\n",
      "Starting the Simulation\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dispatch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([row\u001b[38;5;241m.\u001b[39mvalues], columns\u001b[38;5;241m=\u001b[39mrow\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m      6\u001b[0m ansys_simulator \u001b[38;5;241m=\u001b[39m AnsysSimulator(analyzer, df)\n\u001b[0;32m----> 7\u001b[0m ansys_results \u001b[38;5;241m=\u001b[39m \u001b[43mansys_simulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# hamiltonian_results = ansys_results[\"sim_results\"]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# H_params_simmed.append(hamiltonian_results)\u001b[39;00m\n",
      "File \u001b[0;32m~/LFL/SQuADDS/SQuADDS/squadds/simulations/ansys_simulator.py:166\u001b[0m, in \u001b[0;36mAnsysSimulator.simulate\u001b[0;34m(self, device_dict)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeom_dict \u001b[38;5;241m=\u001b[39m Dict(\n\u001b[1;32m    158\u001b[0m         qubit_geoms\u001b[38;5;241m=\u001b[39mqubit_geoms,\n\u001b[1;32m    159\u001b[0m         cavity_geoms\u001b[38;5;241m=\u001b[39mcavity_geoms\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_dict \u001b[38;5;241m=\u001b[39m Dict(\n\u001b[1;32m    162\u001b[0m         qubit_setup\u001b[38;5;241m=\u001b[39mqubit_setup,\n\u001b[1;32m    163\u001b[0m         cavity_setup\u001b[38;5;241m=\u001b[39mcavity_setup\n\u001b[1;32m    164\u001b[0m     )\n\u001b[0;32m--> 166\u001b[0m     return_df, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlom_analysis_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepr_analysis_obj \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_whole_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mLOM_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqubit_setup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43meigenmode_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcavity_setup\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Handle non-qubit_cavity object case\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# have a non-qubit_cavity object\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     design_options \u001b[38;5;241m=\u001b[39m get_first_element_if_series(device_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdesign_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/LFL/SQuADDS/SQuADDS/squadds/simulations/objects.py:89\u001b[0m, in \u001b[0;36msimulate_whole_device\u001b[0;34m(design, device_dict, eigenmode_options, LOM_options, open_gui)\u001b[0m\n\u001b[1;32m     86\u001b[0m design\u001b[38;5;241m.\u001b[39mdelete_all_components()\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coupler_type\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 89\u001b[0m     emode_df, emode_obj \u001b[38;5;241m=\u001b[39m \u001b[43mrun_eigenmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcavity_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meigenmode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     lom_df, lom_obj \u001b[38;5;241m=\u001b[39m run_xmon_LOM(design, cross_dict, LOM_options)\n\u001b[1;32m     91\u001b[0m     data \u001b[38;5;241m=\u001b[39m get_sim_results(emode_df \u001b[38;5;241m=\u001b[39m emode_df, lom_df \u001b[38;5;241m=\u001b[39m lom_df)\n",
      "File \u001b[0;32m~/LFL/SQuADDS/SQuADDS/squadds/simulations/objects.py:271\u001b[0m, in \u001b[0;36mrun_eigenmode\u001b[0;34m(design, geometry_dict, sim_options)\u001b[0m\n\u001b[1;32m    268\u001b[0m claw \u001b[38;5;241m=\u001b[39m create_claw(geometry_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaw_opts\u001b[39m\u001b[38;5;124m\"\u001b[39m], cpw_length, design)\n\u001b[1;32m    269\u001b[0m config \u001b[38;5;241m=\u001b[39m SimulationConfig(min_converged_passes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 271\u001b[0m epra, hfss \u001b[38;5;241m=\u001b[39m \u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m hfss\u001b[38;5;241m.\u001b[39mclean_active_design()\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# setup = set_simulation_hyperparameters(epra, config)\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m# [\"setup\"]\u001b[39;00m\n",
      "File \u001b[0;32m~/LFL/SQuADDS/SQuADDS/squadds/simulations/objects.py:519\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(design, config)\u001b[0m\n\u001b[1;32m    517\u001b[0m hfss \u001b[38;5;241m=\u001b[39m epra\u001b[38;5;241m.\u001b[39msim\u001b[38;5;241m.\u001b[39mrenderer\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting the Simulation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 519\u001b[0m \u001b[43mhfss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    520\u001b[0m hfss\u001b[38;5;241m.\u001b[39mnew_ansys_design(config\u001b[38;5;241m.\u001b[39mdesign_name, config\u001b[38;5;241m.\u001b[39msim_type)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m epra, hfss\n",
      "File \u001b[0;32m~/LFL/SQuADDS/test_squadds/src/qiskit-metal/qiskit_metal/renderers/renderer_base/renderer_base.py:378\u001b[0m, in \u001b[0;36mQRenderer.start\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_renderer()\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# TODO: move the code line below to inside the `if force or not initiated`,\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m#  but only after the TODO before the `if` is completed\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# try to initialize the renderer\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitiated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initiate_renderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitiated\n",
      "File \u001b[0;32m~/LFL/SQuADDS/test_squadds/src/qiskit-metal/qiskit_metal/renderers/renderer_ansys/ansys_renderer.py:303\u001b[0m, in \u001b[0;36mQAnsysRenderer._initiate_renderer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03mOpen a session of the default Ansys EDT.\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03mEstablishes the connection to the App and Desktop only.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m# test if ansys is open\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# import psutil\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# booted = False\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# need to make it so that it waits for the Ansys boot to end\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# after opening, should establish a connection (able to create a new project)\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrapp \u001b[38;5;241m=\u001b[39m \u001b[43mHfssApp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrdesktop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrapp\u001b[38;5;241m.\u001b[39mget_app_desktop()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrdesktop\u001b[38;5;241m.\u001b[39mproject_count() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/qiskit-metal-env/lib/python3.11/site-packages/pyEPR/ansys.py:382\u001b[0m, in \u001b[0;36mHfssApp.__init__\u001b[0;34m(self, ProgID)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m Connect to IDispatch-based COM object.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m     Parameter is the ProgID or CLSID of the COM object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m \n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28msuper\u001b[39m(HfssApp, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_app \u001b[38;5;241m=\u001b[39m \u001b[43mDispatch\u001b[49m(ProgID)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dispatch' is not defined"
     ]
    }
   ],
   "source": [
    "H_params_simmed = []\n",
    "\n",
    "for index, row in designs_df.iterrows():\n",
    "    print(f\"Simulating design {index}\")\n",
    "    df = pd.DataFrame([row.values], columns=row.index)\n",
    "    ansys_simulator = AnsysSimulator(analyzer, df)\n",
    "    ansys_results = ansys_simulator.simulate(df)\n",
    "    # hamiltonian_results = ansys_results[\"sim_results\"]\n",
    "    # H_params_simmed.append(hamiltonian_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model used in this example but with its hyperparameters optimized, I was able to get the following results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <div style=\"display: inline-flex; justify-content: center; align-items: center; gap: 20px;\">\n",
    "    <div style=\"flex: 1; text-align: center;\">\n",
    "      <img src=\"figures/ga.png\" alt=\"Figure 1\" style=\"width: 80%;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 1; text-align: center;\">\n",
    "      <img src=\"figures/kc.png\" alt=\"Figure 2\" style=\"width: 80%;\">\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palace Simulation\n",
    "\n",
    "If you don't have access to Ansys, you can use the [`palace`](https://awslabs.github.io/palace/) simulator to simulate the qubit-cavity system.\n",
    "\n",
    "We are actively working on developing robust, accurate, and stable simulations using the `palace` backend in collaboration with our friends at the [SQDLab](https://www.sqdlab.org/). \n",
    "\n",
    "In the meantime, we encourage you to explore `palace` on your own with the following resources:\n",
    "\n",
    "- **[Palace Documentation](https://awslabs.github.io/palace/):** Official documentation for the `palace` simulator.\n",
    "- **[Palace Installation Guide](https://lfl-lab.github.io/SQuADDS/source/resources/palace.html):** Step-by-step instructions on how to install `palace` on all platforms.\n",
    "- **[Palace Simulation with Qiskit Metal](https://github.com/sqdlab/SQDMetal):** A simulation framework for using `palace` from `qiskit-metal`.\n",
    "\n",
    "These resources should help you get started with `palace` and enable you to perform simulations effectively until our enhanced integration is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the ML Model to HuggingFace\n",
    "\n",
    "Once you have developed a model that you are happy with and ideally performs really well, you can deploy it to HuggingFace for others to use.\n",
    "\n",
    "HuggingFace makes it ridiculously easy to deploy an ML model. All you need to do is:\n",
    "\n",
    "1. Load the model.\n",
    "2. Save the model in the format required by HuggingFace.\n",
    "\n",
    "```python\n",
    "model.save(f\"hf://{hf_username}/{model_name}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_dnn = load_model(\"models/simple_dnn.keras\")\n",
    "model_dnn.save(\"hf://shanto268/qiskit-fall-fest-2024-test-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your model is **REALLYYYYY good**, then send me an [email](mailto:shanto@usc.edu) with the link to your model and I will add it to the SQuADDS ML model collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps...\n",
    "\n",
    "Please contribute to [SQuADDS!](https://lfl-lab.github.io/SQuADDS/source/resources/contribute.html)\n",
    "\n",
    "Best of luck with your final project and we look forward to seeing what you create!\n",
    "\n",
    "Apply to [USC Physics PhD program](https://dornsife.usc.edu/physics/)! ✌ ️(Deadline: Dec 15, 2024) [**No Application Fee**]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='width: 100%; background-color:#3cb1c2;color:#324344;padding-left: 10px; padding-bottom: 10px; padding-right: 10px; padding-top: 5px'>\n",
    "    <h3>This SQuADDS tutorial was prepared for the Qiskit Fall Fest 2024</h3>\n",
    "    <p>Developed by Sadman Ahmed Shanto</p>\n",
    "    <p>This tutorial is written by Sadman Ahmed Shanto</p> \n",
    "    <p>&copy; Copyright Sadman Ahmed Shanto & Eli Levenson-Falk 2024.</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit-metal-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
